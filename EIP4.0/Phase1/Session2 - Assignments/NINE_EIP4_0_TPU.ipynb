{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "NINE_EIP4_0_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LWfSl03Yghsy"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksasi/EIP/blob/master/EIP4.0/Phase1/Session2%20-%20Assignments/NINE_EIP4_0_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jhp8pOl0z1ue",
        "outputId": "8f2cfa91-ab5a-43d3-cf6f-4c0bbbe480ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python -V"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p-Kvqv7hz1i7",
        "outputId": "2ae1a52c-3310-4ed6-8352-2fae4cbf6e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.4)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (42.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/48/50934afa81c9ab6d68acc19c1c0543f765699fa4e3a36d675baa97816bb1/google_auth-1.8.1-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.8.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed google-auth-1.8.1 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0SJyVpgSxHt4",
        "outputId": "eeedbb26-fa47-44cb-a496-975bf1b0746e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "print(tf.version.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eBp9Gb2e0udy",
        "colab": {}
      },
      "source": [
        "#tf.compat.v1.enable_eager_execution()\n",
        "tf.compat.v1.disable_eager_execution() ## https://github.com/tensorflow/tensorflow/issues/34235 and https://github.com/huan/tensorflow-handbook-tpu/issues/1 for TPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YlEUplvoxKAT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e65f64e5-a4bd-459d-ae2a-7186556486b1"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I6Y9Va-xxMXG",
        "outputId": "8ba7f8b2-abb9-40a7-c5ec-1e5adbbc2111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f187c7ae908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lxDZxPhhxOgO",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3HzMqbTnxQQW",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7LdYiW6ixR9e",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = utils.to_categorical(y_train, 10)\n",
        "Y_test = utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rFR0F9j0xVp2",
        "outputId": "133791c4-2e51-45c8-d316-2353299dc22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ28Hg143Yyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Activation\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        " \n",
        "  model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', input_shape=(28,28,1), use_bias = False)) #26\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', use_bias = False)) #24\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(filters = 10, kernel_size = (1, 1), activation='relu', use_bias = False)) #22\n",
        "\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))#11\n",
        "\n",
        "  model.add(Conv2D(filters = 12, kernel_size = (3, 3), activation='relu', use_bias = False))#9\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(filters = 14, kernel_size = (3, 3), activation='relu', use_bias = False))#7\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(filters = 14, kernel_size = (3, 3), activation='relu', use_bias = False))#7\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', use_bias = False))#7\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', use_bias = False))#7\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(filters = 10, kernel_size = (1, 1), activation='relu', use_bias = False))#3\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(filters = 10, kernel_size = (2, 2)))\n",
        "  #model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08ndjp_53-_q",
        "colab_type": "text"
      },
      "source": [
        "### Train on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHXFbrZe3yTX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "6d1de043-1583-4da1-9b49-349c72c17d5f"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# TF 2.0\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_host(resolver.master())\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.3), metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system %s has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "INFO:tensorflow:Initializing the TPU system: 10.28.135.2:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.28.135.2:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7823539333074611377)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13346691229328149447)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16405287778467525800)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7964849476584623749)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1938216001776309135)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10345329279843387091)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12146902687259572668)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10719010915678581956)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9674323594529953622)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 10374798224766243427)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5327681427153639148)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDpXf4YQxXRm",
        "outputId": "c1e8d8c3-eb6b-431c-ecb3-2aac54d04060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 32)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 10)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 10, 10, 12)        1080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 10, 10, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 10, 10, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 14)          1512      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 14)          56        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 8, 8, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 6, 6, 14)          1764      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 6, 6, 14)          56        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 6, 6, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 16)          2016      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 2, 2, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 2, 2, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 2, 2, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 2, 2, 10)          160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 2, 2, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 2, 2, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 1, 1, 10)          410       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,838\n",
            "Trainable params: 14,578\n",
            "Non-trainable params: 260\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L2IicGJ4x3Be",
        "outputId": "d5260336-01be-4a41-ac68-869bf982a797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.3 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "\n",
        "model.fit(X_train.astype(np.float32), Y_train.astype(np.float32), batch_size=128, steps_per_epoch=468, epochs=20, verbose=1, validation_data=(X_test.astype(np.float32), Y_test.astype(np.float32)), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.3.\n",
            "Epoch 1/20\n",
            "461/468 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.8289INFO:tensorflow:Running validation at fit epoch: 0\n",
            "79/79 [==============================] - 5s 64ms/step\n",
            "79/79 [==============================] - 5s 64ms/step\n",
            "468/468 [==============================] - 13s 28ms/step - loss: 0.4965 - accuracy: 0.8302 - val_loss: 0.1080 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.2274450341.\n",
            "Epoch 2/20\n",
            "466/468 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9132INFO:tensorflow:Running validation at fit epoch: 1\n",
            "79/79 [==============================] - 6s 77ms/step\n",
            "79/79 [==============================] - 6s 77ms/step\n",
            "468/468 [==============================] - 12s 27ms/step - loss: 0.2456 - accuracy: 0.9131 - val_loss: 0.0615 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1831501832.\n",
            "Epoch 3/20\n",
            "465/468 [============================>.] - ETA: 0s - loss: 0.2043 - accuracy: 0.9263INFO:tensorflow:Running validation at fit epoch: 2\n",
            "79/79 [==============================] - 7s 91ms/step\n",
            "79/79 [==============================] - 7s 91ms/step\n",
            "468/468 [==============================] - 14s 30ms/step - loss: 0.2041 - accuracy: 0.9264 - val_loss: 0.0458 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.153295861.\n",
            "Epoch 4/20\n",
            "463/468 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9290INFO:tensorflow:Running validation at fit epoch: 3\n",
            "79/79 [==============================] - 8s 99ms/step\n",
            "79/79 [==============================] - 8s 99ms/step\n",
            "468/468 [==============================] - 15s 32ms/step - loss: 0.1892 - accuracy: 0.9291 - val_loss: 0.0448 - val_accuracy: 0.9867\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1318101933.\n",
            "Epoch 5/20\n",
            "461/468 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9335INFO:tensorflow:Running validation at fit epoch: 4\n",
            "79/79 [==============================] - 9s 113ms/step\n",
            "79/79 [==============================] - 9s 113ms/step\n",
            "468/468 [==============================] - 17s 37ms/step - loss: 0.1749 - accuracy: 0.9337 - val_loss: 0.0387 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1156069364.\n",
            "Epoch 6/20\n",
            "461/468 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9349INFO:tensorflow:Running validation at fit epoch: 5\n",
            "79/79 [==============================] - 10s 130ms/step\n",
            "79/79 [==============================] - 10s 130ms/step\n",
            "468/468 [==============================] - 19s 41ms/step - loss: 0.1674 - accuracy: 0.9352 - val_loss: 0.0383 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1029512697.\n",
            "Epoch 7/20\n",
            "465/468 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9386INFO:tensorflow:Running validation at fit epoch: 6\n",
            "79/79 [==============================] - 11s 139ms/step\n",
            "79/79 [==============================] - 11s 139ms/step\n",
            "468/468 [==============================] - 20s 43ms/step - loss: 0.1591 - accuracy: 0.9388 - val_loss: 0.0366 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0927930715.\n",
            "Epoch 8/20\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9383INFO:tensorflow:Running validation at fit epoch: 7\n",
            "79/79 [==============================] - 12s 155ms/step\n",
            "79/79 [==============================] - 12s 155ms/step\n",
            "468/468 [==============================] - 23s 48ms/step - loss: 0.1576 - accuracy: 0.9383 - val_loss: 0.0342 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0844594595.\n",
            "Epoch 9/20\n",
            "459/468 [============================>.] - ETA: 0s - loss: 0.1550 - accuracy: 0.9392INFO:tensorflow:Running validation at fit epoch: 8\n",
            "79/79 [==============================] - 13s 170ms/step\n",
            "79/79 [==============================] - 13s 170ms/step\n",
            "468/468 [==============================] - 24s 52ms/step - loss: 0.1543 - accuracy: 0.9393 - val_loss: 0.0347 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0774993542.\n",
            "Epoch 10/20\n",
            "464/468 [============================>.] - ETA: 0s - loss: 0.1526 - accuracy: 0.9396INFO:tensorflow:Running validation at fit epoch: 9\n",
            "79/79 [==============================] - 15s 187ms/step\n",
            "79/79 [==============================] - 15s 187ms/step\n",
            "468/468 [==============================] - 27s 57ms/step - loss: 0.1524 - accuracy: 0.9397 - val_loss: 0.0344 - val_accuracy: 0.9890\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0715990453.\n",
            "Epoch 11/20\n",
            "463/468 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9399INFO:tensorflow:Running validation at fit epoch: 10\n",
            "79/79 [==============================] - 16s 206ms/step\n",
            "79/79 [==============================] - 16s 206ms/step\n",
            "468/468 [==============================] - 29s 62ms/step - loss: 0.1478 - accuracy: 0.9399 - val_loss: 0.0324 - val_accuracy: 0.9899\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0665335995.\n",
            "Epoch 12/20\n",
            "461/468 [============================>.] - ETA: 0s - loss: 0.1438 - accuracy: 0.9414INFO:tensorflow:Running validation at fit epoch: 11\n",
            "79/79 [==============================] - 18s 224ms/step\n",
            "79/79 [==============================] - 18s 224ms/step\n",
            "468/468 [==============================] - 31s 67ms/step - loss: 0.1432 - accuracy: 0.9416 - val_loss: 0.0312 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0621375311.\n",
            "Epoch 13/20\n",
            "461/468 [============================>.] - ETA: 0s - loss: 0.1464 - accuracy: 0.9421INFO:tensorflow:Running validation at fit epoch: 12\n",
            "79/79 [==============================] - 20s 249ms/step\n",
            "79/79 [==============================] - 20s 249ms/step\n",
            "468/468 [==============================] - 34s 73ms/step - loss: 0.1460 - accuracy: 0.9422 - val_loss: 0.0314 - val_accuracy: 0.9901\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0582863804.\n",
            "Epoch 14/20\n",
            "465/468 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9413INFO:tensorflow:Running validation at fit epoch: 13\n",
            "79/79 [==============================] - 21s 270ms/step\n",
            "79/79 [==============================] - 21s 270ms/step\n",
            "468/468 [==============================] - 37s 79ms/step - loss: 0.1431 - accuracy: 0.9415 - val_loss: 0.0308 - val_accuracy: 0.9906\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.054884742.\n",
            "Epoch 15/20\n",
            "460/468 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9434INFO:tensorflow:Running validation at fit epoch: 14\n",
            "79/79 [==============================] - 23s 294ms/step\n",
            "79/79 [==============================] - 23s 294ms/step\n",
            "468/468 [==============================] - 40s 86ms/step - loss: 0.1372 - accuracy: 0.9436 - val_loss: 0.0316 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0518582541.\n",
            "Epoch 16/20\n",
            "463/468 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9442INFO:tensorflow:Running validation at fit epoch: 15\n",
            "79/79 [==============================] - 24s 307ms/step\n",
            "79/79 [==============================] - 24s 307ms/step\n",
            "468/468 [==============================] - 42s 89ms/step - loss: 0.1396 - accuracy: 0.9442 - val_loss: 0.0290 - val_accuracy: 0.9909\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0491480996.\n",
            "Epoch 17/20\n",
            "465/468 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.9433INFO:tensorflow:Running validation at fit epoch: 16\n",
            "79/79 [==============================] - 28s 354ms/step\n",
            "79/79 [==============================] - 28s 354ms/step\n",
            "468/468 [==============================] - 47s 100ms/step - loss: 0.1346 - accuracy: 0.9433 - val_loss: 0.0289 - val_accuracy: 0.9918\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0467071462.\n",
            "Epoch 18/20\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9435INFO:tensorflow:Running validation at fit epoch: 17\n",
            "79/79 [==============================] - 29s 361ms/step\n",
            "79/79 [==============================] - 29s 361ms/step\n",
            "468/468 [==============================] - 49s 104ms/step - loss: 0.1366 - accuracy: 0.9435 - val_loss: 0.0291 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0444971818.\n",
            "Epoch 19/20\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9434INFO:tensorflow:Running validation at fit epoch: 18\n",
            "79/79 [==============================] - 30s 381ms/step\n",
            "79/79 [==============================] - 30s 381ms/step\n",
            "468/468 [==============================] - 51s 110ms/step - loss: 0.1365 - accuracy: 0.9435 - val_loss: 0.0267 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0424868999.\n",
            "Epoch 20/20\n",
            "466/468 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.9432INFO:tensorflow:Running validation at fit epoch: 19\n",
            "79/79 [==============================] - 33s 412ms/step\n",
            "79/79 [==============================] - 33s 412ms/step\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.1355 - accuracy: 0.9432 - val_loss: 0.0279 - val_accuracy: 0.9915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1873dfecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WLxlW9ufyQiO",
        "outputId": "53cff5cd-6e11-42b6-8d64-0def5f2b21d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.028136574419381367, 0.99130005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m2qDl21ozBnW",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}