{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PersonAttributes_Identification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZJetvvDKVo6",
        "colab_type": "text"
      },
      "source": [
        "# PersonAttributes Identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKTH3juBTUqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlabePyfKjCe",
        "colab_type": "text"
      },
      "source": [
        "## Import the dataset and setup train and valid generators with augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igeJWiJIT0ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install fastparquet and Pillow files. These would help to store train, valid dataframes and use Auto augment policies. Storage of train , valid dataframes after train,valid split is important to prevent data leak when the weights were loaded and trained again.\n",
        "\n",
        "!pip install fastparquet\n",
        "!pip install Pillow -U"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load all libraries and use tensorflow 2.0 in colab environment\n",
        "\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_2sndZ42QtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use auto-augment policies from \n",
        "\n",
        "# Ref : https://towardsdatascience.com/how-to-improve-your-image-classifier-with-googles-autoaugment-77643f0be0c9\n",
        "# Ref : https://github.com/DeepVoltaire/AutoAugment\n",
        "# Ref : https://arxiv.org/abs/1805.09501v1\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "class ImageNetPolicy(object):\n",
        "    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n",
        "        Example:\n",
        "        >>> policy = ImageNetPolicy()\n",
        "        >>> transformed = policy(image)\n",
        "        Example as a PyTorch Transform:\n",
        "        >>> transform=transforms.Compose([\n",
        "        >>>     transforms.Resize(256),\n",
        "        >>>     ImageNetPolicy(),\n",
        "        >>>     transforms.ToTensor()])\n",
        "    \"\"\"\n",
        "    def __init__(self, fillcolor=(128, 128, 128)):\n",
        "        self.policies = [\n",
        "            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
        "            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n",
        "            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n",
        "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
        "\n",
        "            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n",
        "            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n",
        "            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n",
        "\n",
        "            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n",
        "            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n",
        "            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n",
        "\n",
        "            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n",
        "            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n",
        "            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n",
        "            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n",
        "\n",
        "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
        "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n",
        "            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
        "        return self.policies[policy_idx](img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"AutoAugment ImageNet Policy\"\n",
        "\n",
        "\n",
        "class CIFAR10Policy(object):\n",
        "    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n",
        "        Example:\n",
        "        >>> policy = CIFAR10Policy()\n",
        "        >>> transformed = policy(image)\n",
        "        Example as a PyTorch Transform:\n",
        "        >>> transform=transforms.Compose([\n",
        "        >>>     transforms.Resize(256),\n",
        "        >>>     CIFAR10Policy(),\n",
        "        >>>     transforms.ToTensor()])\n",
        "    \"\"\"\n",
        "    def __init__(self, fillcolor=(128, 128, 128)):\n",
        "        self.policies = [\n",
        "            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n",
        "            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n",
        "            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n",
        "            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n",
        "            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n",
        "\n",
        "            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n",
        "            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n",
        "            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n",
        "            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n",
        "            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n",
        "\n",
        "            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n",
        "            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n",
        "            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n",
        "            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n",
        "            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n",
        "\n",
        "            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n",
        "            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n",
        "            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n",
        "            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n",
        "            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n",
        "\n",
        "            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n",
        "            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n",
        "            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n",
        "            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n",
        "            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
        "        return self.policies[policy_idx](img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"AutoAugment CIFAR10 Policy\"\n",
        "\n",
        "\n",
        "class SVHNPolicy(object):\n",
        "    \"\"\" Randomly choose one of the best 25 Sub-policies on SVHN.\n",
        "        Example:\n",
        "        >>> policy = SVHNPolicy()\n",
        "        >>> transformed = policy(image)\n",
        "        Example as a PyTorch Transform:\n",
        "        >>> transform=transforms.Compose([\n",
        "        >>>     transforms.Resize(256),\n",
        "        >>>     SVHNPolicy(),\n",
        "        >>>     transforms.ToTensor()])\n",
        "    \"\"\"\n",
        "    def __init__(self, fillcolor=(128, 128, 128)):\n",
        "        self.policies = [\n",
        "            SubPolicy(0.9, \"shearX\", 4, 0.2, \"invert\", 3, fillcolor),\n",
        "            SubPolicy(0.9, \"shearY\", 8, 0.7, \"invert\", 5, fillcolor),\n",
        "            SubPolicy(0.6, \"equalize\", 5, 0.6, \"solarize\", 6, fillcolor),\n",
        "            SubPolicy(0.9, \"invert\", 3, 0.6, \"equalize\", 3, fillcolor),\n",
        "            SubPolicy(0.6, \"equalize\", 1, 0.9, \"rotate\", 3, fillcolor),\n",
        "\n",
        "            SubPolicy(0.9, \"shearX\", 4, 0.8, \"autocontrast\", 3, fillcolor),\n",
        "            SubPolicy(0.9, \"shearY\", 8, 0.4, \"invert\", 5, fillcolor),\n",
        "            SubPolicy(0.9, \"shearY\", 5, 0.2, \"solarize\", 6, fillcolor),\n",
        "            SubPolicy(0.9, \"invert\", 6, 0.8, \"autocontrast\", 1, fillcolor),\n",
        "            SubPolicy(0.6, \"equalize\", 3, 0.9, \"rotate\", 3, fillcolor),\n",
        "\n",
        "            SubPolicy(0.9, \"shearX\", 4, 0.3, \"solarize\", 3, fillcolor),\n",
        "            SubPolicy(0.8, \"shearY\", 8, 0.7, \"invert\", 4, fillcolor),\n",
        "            SubPolicy(0.9, \"equalize\", 5, 0.6, \"translateY\", 6, fillcolor),\n",
        "            SubPolicy(0.9, \"invert\", 4, 0.6, \"equalize\", 7, fillcolor),\n",
        "            SubPolicy(0.3, \"contrast\", 3, 0.8, \"rotate\", 4, fillcolor),\n",
        "\n",
        "            SubPolicy(0.8, \"invert\", 5, 0.0, \"translateY\", 2, fillcolor),\n",
        "            SubPolicy(0.7, \"shearY\", 6, 0.4, \"solarize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"invert\", 4, 0.8, \"rotate\", 4, fillcolor),\n",
        "            SubPolicy(0.3, \"shearY\", 7, 0.9, \"translateX\", 3, fillcolor),\n",
        "            SubPolicy(0.1, \"shearX\", 6, 0.6, \"invert\", 5, fillcolor),\n",
        "\n",
        "            SubPolicy(0.7, \"solarize\", 2, 0.6, \"translateY\", 7, fillcolor),\n",
        "            SubPolicy(0.8, \"shearY\", 4, 0.8, \"invert\", 8, fillcolor),\n",
        "            SubPolicy(0.7, \"shearX\", 9, 0.8, \"translateY\", 3, fillcolor),\n",
        "            SubPolicy(0.8, \"shearY\", 5, 0.7, \"autocontrast\", 3, fillcolor),\n",
        "            SubPolicy(0.7, \"shearX\", 2, 0.1, \"invert\", 5, fillcolor)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
        "        return self.policies[policy_idx](img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"AutoAugment SVHN Policy\"\n",
        "\n",
        "\n",
        "class SubPolicy(object):\n",
        "    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n",
        "        ranges = {\n",
        "            \"shearX\": np.linspace(0, 0.3, 10),\n",
        "            \"shearY\": np.linspace(0, 0.3, 10),\n",
        "            \"translateX\": np.linspace(0, 150 / 331, 10),\n",
        "            \"translateY\": np.linspace(0, 150 / 331, 10),\n",
        "            \"rotate\": np.linspace(0, 30, 10),\n",
        "            \"color\": np.linspace(0.0, 0.9, 10),\n",
        "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n",
        "            \"solarize\": np.linspace(256, 0, 10),\n",
        "            \"contrast\": np.linspace(0.0, 0.9, 10),\n",
        "            \"sharpness\": np.linspace(0.0, 0.9, 10),\n",
        "            \"brightness\": np.linspace(0.0, 0.9, 10),\n",
        "            \"autocontrast\": [0] * 10,\n",
        "            \"equalize\": [0] * 10,\n",
        "            \"invert\": [0] * 10\n",
        "        }\n",
        "\n",
        "        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n",
        "        def rotate_with_fill(img, magnitude):\n",
        "            rot = img.convert(\"RGBA\").rotate(magnitude)\n",
        "            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n",
        "\n",
        "        func = {\n",
        "            \"shearX\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n",
        "                Image.BICUBIC, fillcolor=fillcolor),\n",
        "            \"shearY\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n",
        "                Image.BICUBIC, fillcolor=fillcolor),\n",
        "            \"translateX\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n",
        "                fillcolor=fillcolor),\n",
        "            \"translateY\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n",
        "                fillcolor=fillcolor),\n",
        "            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n",
        "            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n",
        "            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n",
        "            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n",
        "            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n",
        "            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n",
        "            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n",
        "        }\n",
        "\n",
        "        self.p1 = p1\n",
        "        self.operation1 = func[operation1]\n",
        "        self.magnitude1 = ranges[operation1][magnitude_idx1]\n",
        "        self.p2 = p2\n",
        "        self.operation2 = func[operation2]\n",
        "        self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n",
        "        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeqPK_x92bVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import pdb\n",
        "#from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a generator using tf.keras.utils.Sequence. The generator also need to apply necessary augmentations and AutoAugment policies.\n",
        "\n",
        "from  skimage import transform\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, augmentations, policy = None, new_shape = (224,224) , batch_size=32, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augmentations\n",
        "        self.policy = policy\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        policy = ImageNetPolicy()\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        #image = np.stack([self.augment(policy(cv2.resize(cv2.imread(item[\"image_path\"]), new_shape))) for _, item in items.iterrows()])\n",
        "        if not self.policy:\n",
        "          image = np.stack([self.augment(cv2.resize(np.array(Image.open(item[\"image_path\"])), new_shape)) for _, item in items.iterrows()])\n",
        "        else:\n",
        "          image = np.stack([self.augment(cv2.resize(np.array(self.policy(Image.open(item[\"image_path\"]))), new_shape)) for _, item in items.iterrows()])\n",
        "\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BCE7ht62aIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform train and test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df_sk, val_df_sk = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df_sk.shape, val_df_sk.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv2sRbcCTmNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store the test , train dataframes as parquet files. This is to prevent data leak. Run this the first time and comment the code so that this is not executed for subsequent runs in Colab.\n",
        "\n",
        "'''import fastparquet\n",
        "train_df_sk.to_parquet('/content/gdrive/My Drive/models/train_df.parquet.gzip', compression='gzip')\n",
        "val_df_sk.to_parquet('/content/gdrive/My Drive/models/val_df.parquet.gzip', compression='gzip')'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fMhTa7UTmRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the parquet files as train and valid data frames.\n",
        "\n",
        "import fastparquet\n",
        "train_df = pd.read_parquet('/content/gdrive/My Drive/models/train_df.parquet.gzip')\n",
        "val_df = pd.read_parquet('/content/gdrive/My Drive/models/val_df.parquet.gzip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show rows form train dataframe\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih650DYHt6Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show rows from valid dataframe\n",
        "\n",
        "val_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAxlsCQr0Zom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjsSXQTEWCam",
        "colab_type": "text"
      },
      "source": [
        "### Train the model with resized 128x128 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks4MRdfm8ZWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Augmenters - Here image augmentations were not being applied as AutoAugment policy is being used subsequently\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop)\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop, CenterCrop, VerticalFlip)\n",
        "\n",
        "def AUGMENTATIONS_INT_TRAIN(input_img, height = 224, width = 224):\n",
        "    seq = Compose([#PadIfNeeded(height + 32,width + 32, p=1),\n",
        "                   RandomCrop(height,width, p=1)\n",
        "                   #HorizontalFlip(p=0.5),\n",
        "                   #Cutout(num_holes=1, max_h_size=8, max_w_size=8, p=0.5)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img\n",
        "\n",
        "def AUGMENTATIONS_INT_TEST(input_img, height = 224, width = 224):\n",
        "    seq = Compose([\n",
        "                   RandomCrop(height,width, p=1)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6hPViDw9XT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmentation lambda functions for train and test\n",
        "\n",
        "AUGMENTATIONS_TRAIN = lambda input_img: AUGMENTATIONS_INT_TRAIN(input_img, height = 128, width = 128)\n",
        "AUGMENTATIONS_TEST = lambda input_img: AUGMENTATIONS_INT_TEST(input_img, height = 128, width = 128)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators. Here CIFRA10 AutoAugment policy is being applied for train generator.\n",
        "\n",
        "new_shape = (128,128)\n",
        "\n",
        "#policy = ImageNetPolicy()\n",
        "policy = CIFAR10Policy()\n",
        "#policy = SVHNPolicy()\n",
        "\n",
        "train_gen = PersonDataGenerator(train_df, policy = policy, batch_size=512, new_shape = new_shape, augmentations = AUGMENTATIONS_TRAIN)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=512, shuffle=False, new_shape = new_shape, augmentations = AUGMENTATIONS_TEST)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BT07aUTMT7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show train images after applying AutoAugment policy\n",
        "train_generator32 = PersonDataGenerator(train_df, policy = policy, batch_size=32, new_shape = new_shape, augmentations = AUGMENTATIONS_TRAIN)\n",
        "\n",
        "x, y = next(iter(train_generator32))\n",
        "\n",
        "plt.figure(figsize=(32, 16))\n",
        "for i, (img, _) in enumerate(zip(x, y['bag_output'])):\n",
        "    plt.subplot(4, 8, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, interpolation=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIZ1CiM6OSSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVk-_XCDM7BQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show valid images , no augmentation or AutoAugment policy is applied for validation dataset.\n",
        "\n",
        "valid_generator32 = PersonDataGenerator(val_df, batch_size=32, new_shape = new_shape, augmentations = AUGMENTATIONS_TRAIN)\n",
        "\n",
        "x, y = next(iter(valid_generator32))\n",
        "\n",
        "plt.figure(figsize=(32, 16))\n",
        "for i, (img, _) in enumerate(zip(x, y['bag_output'])):\n",
        "    plt.subplot(4, 8, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, interpolation=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7vIwxKrZqoY",
        "colab_type": "text"
      },
      "source": [
        "### Create ResNet18 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHRSzngctAG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classification models Zoo - Keras (and TensorFlow Keras) - https://github.com/qubvel/classification_models\n",
        "\n",
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAaJwq8nZ0EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtain ResNet18 model without the classification head\n",
        "\n",
        "from classification_models.tfkeras import Classifiers\n",
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "backbone = ResNet18((None, None, 3), weights=None, include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the classification head to ResNet18\n",
        "\n",
        "'''backbone = VGG16(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")'''\n",
        "\n",
        "neck = backbone.output\n",
        "neck = GlobalAveragePooling2D()(neck)\n",
        "#neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    #neck = Dropout(0.2)(in_layer)\n",
        "    #neck = Dense(256, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=None)(neck)\n",
        "    neck = in_layer\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgeVyjUc7Fva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define learning rate scheduler. Step learning rate is being used.\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
        "def scheduler(epoch):\n",
        "    if epoch < 20:\n",
        "        return 0.1\n",
        "    if 20 <= epoch < 40:\n",
        "        return 0.02\n",
        "    if 40 <= epoch < 60:\n",
        "        return 0.004\n",
        "    if epoch >= 60 :\n",
        "        return 0.0008\n",
        "\n",
        "# The below piece wise linear learning rate schedule defined is not used.\n",
        "def lr_schedule(epoch):\n",
        "  lr = 1.0/4.0\n",
        "  scale_224 = 224 / 512\n",
        "  scale_288 = 128 / 512\n",
        "  lr = np.interp(epoch, [0, 5, 14, 16, 27, 32, 33, 35], [lr, lr*2,  lr * scale_224, lr / 10 * scale_224, lr / 100 * scale_224, lr / 100 * scale_288, lr / 1000 * scale_288, lr / 1000 * scale_288])\n",
        "  print(lr)\n",
        "  return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss_weights = {'gender_output': 1.0, 'image_quality_output': 0.0, 'age_output': 0.0, 'weight_output': 0.0, 'bag_output': 0.0, 'footwear_output': 0.0, 'pose_output': 0.0, 'emotion_output': 0.0}\n",
        "\n",
        "# Define optimizer and compile the model\n",
        "\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    #loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8kx6NcnucGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyEBAp5wsxBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class_weights = [{ 0 :1.28, 1 :1.0}, { 0 :1.0, 1 :3.31, 2: 1.97}, { 0 : 2.18 , 1 : 1.0, 2: 1.59, 3: 3.61, 4: 7.51 } ,{ 0 :1.0, 1 :9.78, 2 :2.72, 3 :10.27}, { 0 :1.66, 1 :5.8, 2: 1.0}, { 0 :1.19, 1 :2.38, 2: 1.0}, { 0 :3.77, 1 :1.0, 2: 2.79}, { 0 :6.56, 1 :6.14, 2: 1.0, 3: 12.25}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model for 100 epochs\n",
        "\n",
        "model.fit_generator(generator=train_gen,validation_data=valid_gen, use_multiprocessing=False,epochs=100, callbacks=[LearningRateScheduler(scheduler, verbose=1)], verbose=1)\n",
        "\n",
        "# model.fit_generator(generator=train_gen,validation_data=valid_gen, use_multiprocessing=False,epochs=35, callbacks=[LearningRateScheduler(lr_schedule, verbose=1)], verbose=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT3WEfhQgYz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size128_AutoAug_all_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_j4YnAZl-_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size128_AutoAug_all_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "87RviH7MwBXN",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX5Z_df8wdWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j2XdLaSWSQF",
        "colab_type": "text"
      },
      "source": [
        "### Train the model with actual sized images i.e. 224x224 sized images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RFONln0wZdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Augmenters\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop)\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop, CenterCrop, VerticalFlip, Normalize, ShiftScaleRotate, RandomSizedCrop, RandomBrightnessContrast)\n",
        "\n",
        "def AUGMENTATIONS_INT_TRAIN(input_img, height = 224, width = 224):\n",
        "    seq = Compose([#PadIfNeeded(height + 32,width + 32, p=1),\n",
        "                   #RandomSizedCrop((64,64),height,width, p=1),\n",
        "                   #Normalize(),\n",
        "                   #ShiftScaleRotate(),\n",
        "                   #RandomBrightnessContrast(),\n",
        "                   RandomCrop(height,width, p=1)\n",
        "                   #HorizontalFlip(p=0.5),\n",
        "                   #Cutout(num_holes=1, max_h_size=8, max_w_size=8, p=0.5)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img\n",
        "\n",
        "def AUGMENTATIONS_INT_TEST(input_img, height = 224, width = 224):\n",
        "    seq = Compose([\n",
        "                   RandomCrop(height,width, p=1)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBzHy6LRwgB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image augmentation lambda functions for train and validation\n",
        "\n",
        "AUGMENTATIONS_TRAIN = lambda input_img: AUGMENTATIONS_INT_TRAIN(input_img, height = 224, width = 224)\n",
        "AUGMENTATIONS_TEST = lambda input_img: AUGMENTATIONS_INT_TEST(input_img, height = 224, width = 224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph7oLJ7mmD4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators. Use CIFAR10 AutoAugment policy.\n",
        "\n",
        "new_shape = (224,224)\n",
        "\n",
        "policy = CIFAR10Policy()\n",
        "\n",
        "train_gen = PersonDataGenerator(train_df, policy = policy, batch_size=128, new_shape = new_shape, augmentations = AUGMENTATIONS_TRAIN)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=128, shuffle=False, new_shape = new_shape, augmentations = AUGMENTATIONS_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi8UCGUuFs4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xXrAmsZ2FFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss_weights = {'gender_output': 5.0, 'image_quality_output': 20.0, 'age_output': 60.0, 'weight_output': 20.0, 'bag_output': 20.0, 'footwear_output': 20.0, 'pose_output': 20.0, 'emotion_output': 5.0}\n",
        "\n",
        "# Checkpoint the best model i.e. model where validation loss improves.\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_Best_1.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model_callbacks=[checkpointer, LearningRateScheduler(scheduler, verbose=1)]\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    #loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0CEIz1lmUbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model for 120 epochs\n",
        "\n",
        "model.fit_generator(generator=train_gen,validation_data=valid_gen, use_multiprocessing=False,epochs=120, callbacks=model_callbacks, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJSE58DbLvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYAGunzDpFAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMDLDQnCWu7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSRxgIBSWvRn",
        "colab_type": "text"
      },
      "source": [
        "### Train the model for 200 epochs with CIFAR10 AutoAugment policy using 224x224 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qJ_54dDdvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define learning rate scheduler. Step learning rate is being used.\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
        "def scheduler(epoch):\n",
        "    if epoch < 40:\n",
        "        return 0.1\n",
        "    if 40 <= epoch < 80:\n",
        "        return 0.02\n",
        "    if 80 <= epoch < 120:\n",
        "        return 0.004\n",
        "    if epoch >= 120 :\n",
        "        return 0.0008"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZrN0bqB2PkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkpoint and save the best model i.e. model with best validation loss\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_Best_2.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model_callbacks=[checkpointer, LearningRateScheduler(scheduler, verbose=1)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCL2-9FFDdtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model for 200 epochs\n",
        "\n",
        "model.fit_generator(generator=train_gen,validation_data=valid_gen, use_multiprocessing=False,epochs=200, callbacks=model_callbacks, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqrZTIiJs_T-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRGoFSZJtCpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTcDrBSDFhro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UFA_TaxXBm8",
        "colab_type": "text"
      },
      "source": [
        "### Train the model for 200 epochs with RandomCrop, HorizontalFlip and Cutout(num_holes=20 and size 8x8) with 224x224 size images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFq3CLR0Fh3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Augmenters - Not using any AutoAugment policies ,but use RandomCrop, HorizontalFlip and Cutout(num_holes=20 and size 8x8) augmentations.\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop)\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop, CenterCrop, VerticalFlip, Normalize, ShiftScaleRotate, RandomSizedCrop, RandomBrightnessContrast)\n",
        "\n",
        "def AUGMENTATIONS_INT_TRAIN(input_img, height = 224, width = 224):\n",
        "    seq = Compose([PadIfNeeded(height + 32,width + 32, p=1),\n",
        "                   #RandomSizedCrop((64,64),height,width, p=1),\n",
        "                   #Normalize(),\n",
        "                   #ShiftScaleRotate(),\n",
        "                   #RandomBrightnessContrast(),\n",
        "                   RandomCrop(height,width, p=1),\n",
        "                   HorizontalFlip(p=0.5),\n",
        "                   Cutout(num_holes=20, max_h_size=8, max_w_size=8, p=0.5)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img\n",
        "\n",
        "def AUGMENTATIONS_INT_TEST(input_img, height = 224, width = 224):\n",
        "    seq = Compose([\n",
        "                   RandomCrop(height,width, p=1)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4NgvGAHFmFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmentation lambda functions\n",
        "\n",
        "AUGMENTATIONS_TRAIN = lambda input_img: AUGMENTATIONS_INT_TRAIN(input_img, height = 224, width = 224)\n",
        "AUGMENTATIONS_TEST = lambda input_img: AUGMENTATIONS_INT_TEST(input_img, height = 224, width = 224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG0X-rYgFukM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "\n",
        "new_shape = (224,224)\n",
        "\n",
        "train_gen = PersonDataGenerator(train_df, policy = None, batch_size=128, new_shape = new_shape, augmentations = AUGMENTATIONS_TRAIN)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=128, shuffle=False, new_shape = new_shape, augmentations = AUGMENTATIONS_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIZ7h5vJr1iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnySiZziFxY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define learning rate scheduler. Step learning rate is being used.\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
        "def scheduler(epoch):\n",
        "    if epoch < 40:\n",
        "        return 0.1\n",
        "    if 40 <= epoch < 80:\n",
        "        return 0.02\n",
        "    if 80 <= epoch < 120:\n",
        "        return 0.004\n",
        "    if epoch >= 120 :\n",
        "        return 0.0008"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCZf7LeY2Xfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkpoint to save the best model i.e. model with best validation accuracy\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_Best_3.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model_callbacks=[checkpointer, LearningRateScheduler(scheduler, verbose=1)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f26dzYHxF0v8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model for 200 epochs\n",
        "\n",
        "model.fit_generator(generator=train_gen,validation_data=valid_gen, use_multiprocessing=False,epochs=200, callbacks=model_callbacks, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6GRhmGnGGru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEmsUURnGKfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw8EvzOWrqSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhC_0U4IXmP8",
        "colab_type": "text"
      },
      "source": [
        "### Train the model for 150 epochs with RandomCrop, HorizontalFlip and Cutout(num_holes=40 and size 8x8) with 224x224 size images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKKS9yHJrqPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Augmenters - No AutoAugment policies, but use RandomCrop, HorizontalFlip and Cutout(num_holes=40 and size 8x8) augmentations.\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop)\n",
        "from albumentations import (Compose, HorizontalFlip, Cutout, PadIfNeeded, RandomCrop, CenterCrop, VerticalFlip, Normalize, ShiftScaleRotate, RandomSizedCrop, RandomBrightnessContrast)\n",
        "\n",
        "def AUGMENTATIONS_INT_TRAIN(input_img, height = 224, width = 224):\n",
        "    seq = Compose([PadIfNeeded(height + 32,width + 32, p=1),\n",
        "                   #RandomSizedCrop((64,64),height,width, p=1),\n",
        "                   #Normalize(),\n",
        "                   #ShiftScaleRotate(),\n",
        "                   #RandomBrightnessContrast(),\n",
        "                   RandomCrop(height,width, p=1),\n",
        "                   HorizontalFlip(p=0.5),\n",
        "                   Cutout(num_holes=40, max_h_size=8, max_w_size=8, p=0.5)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img\n",
        "\n",
        "def AUGMENTATIONS_INT_TEST(input_img, height = 224, width = 224):\n",
        "    seq = Compose([\n",
        "                   RandomCrop(height,width, p=1)\n",
        "                  ], p=1)\n",
        "    output_img = seq(image = input_img)['image']\n",
        "    return output_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI9NwqumrqND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmentation lambda functions\n",
        "\n",
        "AUGMENTATIONS_TRAIN = lambda input_img: AUGMENTATIONS_INT_TRAIN(input_img, height = 224, width = 224)\n",
        "AUGMENTATIONS_TEST = lambda input_img: AUGMENTATIONS_INT_TEST(input_img, height = 224, width = 224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqQeT22Vr40E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "\n",
        "new_shape = (224,224)\n",
        "\n",
        "train_gen = PersonDataGenerator(train_df, policy = None, batch_size=128, new_shape = new_shape, augmentations = AUGMENTATIONS_TRAIN)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=128, shuffle=False, new_shape = new_shape, augmentations = AUGMENTATIONS_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1GUkKLJr5Ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define learning rate scheduler. Step learning rate is being used.\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
        "def scheduler(epoch):\n",
        "    if epoch < 40:\n",
        "        return 0.1\n",
        "    if 40 <= epoch < 80:\n",
        "        return 0.02\n",
        "    if 80 <= epoch < 120:\n",
        "        return 0.004\n",
        "    if epoch >= 120 :\n",
        "        return 0.0008"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o93JGfOur5Oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkpoint the best model i.e. where validation loss is best/minimum\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_Best_4.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model_callbacks=[checkpointer, LearningRateScheduler(scheduler, verbose=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6_s0hqFr5MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(generator=train_gen,validation_data=valid_gen, use_multiprocessing=False,epochs=150, callbacks=model_callbacks, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36nJo0bHr5IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_4.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ8Wtybyr5CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyOdoBv4YE2V",
        "colab_type": "text"
      },
      "source": [
        "### Load the best model and perform evaludation on the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JE5E81dDq4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQgvdR2EF4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from classification_models.tfkeras import Classifiers\n",
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "backbone = ResNet18((None, None, 3), weights=None, include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg0IyPysr4-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "neck = backbone.output\n",
        "neck = GlobalAveragePooling2D()(neck)\n",
        "#neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    #neck = Dropout(0.2)(in_layer)\n",
        "    #neck = Dense(256, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=None)(neck)\n",
        "    neck = in_layer\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "best_model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTcKYpVIFKQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "best_model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    #loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvI5mZHr48H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the model with best weights\n",
        "\n",
        "best_model.load_weights(\"/content/gdrive/My Drive/models/EIP4_Assign5_Size224_all_Best_3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3fcfnMWE99m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMayhTj1r46N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtain results on validation dataset\n",
        "\n",
        "val_results = best_model.evaluate(x=valid_gen, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C-Vi-rIr43f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print model metrics\n",
        "\n",
        "print(best_model.metrics_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nfIapIMFjo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print validation results\n",
        "\n",
        "print(val_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdRUsVRRF8m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the dictionary with metric names and metric values\n",
        "\n",
        "result_dict = dict(zip(best_model.metrics_names, val_results))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfGh1zb2I1qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print results dictionary\n",
        "\n",
        "print(result_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqyH3YxGGI3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print validation accuracy results\n",
        "\n",
        "import sys\n",
        "sys.stdout.write(\"\\033[0;0m\")\n",
        "for key,value in result_dict.items():\n",
        "  if 'accuracy' in str(key):\n",
        "    sys.stdout.write(\"\\033[1;32m\")\n",
        "    sys.stdout.write(\"\\033[;1m\")\n",
        "    print('{} : {}\\n'.format(key,value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TGTzNipYnrN",
        "colab_type": "text"
      },
      "source": [
        "## References & Attributions:\n",
        "\n",
        "\n",
        "\n",
        "*   https://github.com/qubvel/classification_models.git\n",
        "*   https://towardsdatascience.com/how-to-improve-your-image-classifier-with-googles-autoaugment-77643f0be0c9\n",
        "*   https://github.com/DeepVoltaire/AutoAugment\n",
        "*   https://arxiv.org/abs/1805.09501v1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7jltD8JZrYW",
        "colab_type": "text"
      },
      "source": [
        "*Disclaimer: The contents of this notebook are used for educational purposes i.e. for learning and research.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9t1QJmXZWNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}